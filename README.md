# Introduction
Source for the workshop paper: E. Markou and C. E. Rasmussen, <em>Bayesian methods for efficient Reinforcement Learning in tabular problems</em>, appearing in the 2019 NIPS Workshop on Biological and Artificial RL.

We compare different Bayesian methods for representing an RL agent's uncertainty about cumulative rewards:

* Bayesian Q-Learning, Dearden et. al., https://www.aaai.org/Papers/AAAI/1998/AAAI98-108.pdf
* The Uncertainty Bellman equation, O'Donoghue et. al., https://arxiv.org/abs/1709.05380
* Posterior Sampling for Reinforcement Learning, Osband et. al., http://papers.nips.cc/paper/5185-more-efficient-reinforcement-learning-via-posterior-sampling
* Our approach based on moment matching, proposed in

